{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-18T12:52:41.534973Z",
     "start_time": "2024-05-18T12:52:41.496601Z"
    }
   },
   "source": [
    "# Установим библиотеку nest_asyncio\n",
    "#!pip install nest_asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import getpass\n",
    "import pandas as pd\n",
    "import openai  # будем использовать для токинизации\n",
    "from typing import Tuple, List\n",
    "from scipy import spatial  # вычисляет сходство векторов\n",
    "import tiktoken\n"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T14:06:07.270884Z",
     "start_time": "2024-05-18T14:06:04.343094Z"
    }
   },
   "cell_type": "code",
   "source": "! unzip automobile_file.zip",
   "id": "66797b5e455153b8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  automobile_file.zip\r\n",
      "  inflating: automobile.csv          \r\n",
      "  inflating: automobile.pickle       \r\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:29:47.069825Z",
     "start_time": "2024-05-18T12:29:47.060626Z"
    }
   },
   "cell_type": "code",
   "source": [
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"  # Модель токенизации от OpenAI\n",
    "GPT_MODEL = \"gpt-3.5-turbo\"  # only matters insofar as it selects which tokenizer to use\n"
   ],
   "id": "e0fa1359c35fc2f",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T13:50:10.938182Z",
     "start_time": "2024-05-18T13:50:09.288062Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.DataFrame()\n",
    "import pickle\n",
    "with open('automobile.pickle', 'rb') as f: \n",
    "    df = pickle.load(f)\n",
    "print(f\"Loaded {df.shape} rows\")"
   ],
   "id": "aef9cc50c68ffe3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded (5384, 2) rows\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:50:41.093266Z",
     "start_time": "2024-05-18T12:50:41.082204Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def relatedness_fn2(x, y):\n",
    "    # print(f\"x={type(x)}\")\n",
    "    # print(f\"y={type(y)}\")\n",
    "    \n",
    "    return 1 - spatial.distance.cosine(x, y)\n",
    "    \n",
    "# Функция поиска\n",
    "def strings_ranked_by_relatedness(\n",
    "    query: str, # пользовательский запрос\n",
    "    df: pd.DataFrame, # DataFrame со столбцами text и embedding (база знаний)\n",
    "    relatedness_fn=relatedness_fn2, # функция схожести, косинусное расстояние\n",
    "    top_n: int = 100 # выбор лучших n-результатов\n",
    ") -> Tuple[List[str], List[float]]: # Функция возвращает кортеж двух списков, первый содержит строки, второй - числа с плавающей запятой\n",
    "    \"\"\"Возвращает строки и схожести, отсортированные от большего к меньшему\"\"\"\n",
    "    print(f\"query='{query}'\")\n",
    "    # Отправляем в OpenAI API пользовательский запрос для токенизации\n",
    "    query_embedding_response = openai.embeddings.create(\n",
    "        model=EMBEDDING_MODEL,\n",
    "        input=query,\n",
    "    )\n",
    "\n",
    "    # Получен токенизированный пользовательский запрос\n",
    "    query_embedding = query_embedding_response.data[0].embedding\n",
    "    #print(f\"query_embedding='{query_embedding}'\")\n",
    "    # Сравниваем пользовательский запрос с каждой токенизированной строкой DataFrame\n",
    "    strings_and_relatednesses = [\n",
    "        (row[\"text\"], relatedness_fn(query_embedding, row[\"embedding\"]))\n",
    "        for i, row in df.iterrows()\n",
    "    ]\n",
    "\n",
    "    # Сортируем по убыванию схожести полученный список\n",
    "    strings_and_relatednesses.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Преобразовываем наш список в кортеж из списков\n",
    "    strings, relatednesses = zip(*strings_and_relatednesses)\n",
    "\n",
    "    # Возвращаем n лучших результатов\n",
    "    return strings[:top_n], relatednesses[:top_n]"
   ],
   "id": "17ea6057654ec085",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:50:11.374716Z",
     "start_time": "2024-05-18T12:50:09.818087Z"
    }
   },
   "cell_type": "code",
   "source": "#strings_ranked_by_relatedness(\"fast car speed\", df, top_n=1)",
   "id": "c75666ff2b655faf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query='fast car speed'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x=<class 'list'>\n",
      "y=<class 'list'>\n",
      "x=<class 'list'>\n",
      "y=<class 'list'>\n",
      "x=<class 'list'>\n",
      "y=<class 'list'>\n",
      "x=<class 'list'>\n",
      "y=<class 'list'>\n",
      "x=<class 'list'>\n",
      "y=<class 'list'>\n",
      "x=<class 'list'>\n",
      "y=<class 'list'>\n",
      "x=<class 'list'>\n",
      "y=<class 'list'>\n",
      "x=<class 'list'>\n",
      "y=<class 'list'>\n",
      "x=<class 'list'>\n",
      "y=<class 'list'>\n",
      "x=<class 'list'>\n",
      "y=<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(('NZ Performance Car\\n\\n==Magazine contents==\\n\\n===Modified car features===\\n\\nThe extent that a car is required to be modified has steadily increased since the first issues. While 300&nbsp;hp was considered to be a huge amount of power when the magazine started, 300&nbsp;kW may not even secure a spot as a feature car, unless the rest of the car is outstanding or unusual.\\n\\nThis is not to say that NZ Performance Car solely focuses on power, but power figures are part of a more holistic approach considered when modifying a car.',),\n",
       " (0.8000849509620129,))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:30:52.335160Z",
     "start_time": "2024-05-18T12:30:46.852589Z"
    }
   },
   "cell_type": "code",
   "source": "os.environ[\"API_TOKEN\"] = getpass.getpass(\"Введите Telegram API Key:\")",
   "id": "cf50d8b35f10cf86",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:30:59.573863Z",
     "start_time": "2024-05-18T12:30:53.546567Z"
    }
   },
   "cell_type": "code",
   "source": "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Введите OpenAI API Key:\")",
   "id": "3b69f254eba6fc37",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:31:01.207325Z",
     "start_time": "2024-05-18T12:31:01.158292Z"
    }
   },
   "cell_type": "code",
   "source": "client = OpenAI(api_key = os.environ.get(\"OPENAI_API_KEY\"))",
   "id": "6c3bec0f5ca94d41",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:55:17.651906Z",
     "start_time": "2024-05-18T12:55:17.636536Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# с этой функцией мы уже знакомы\n",
    "def num_tokens(text: str, model: str = GPT_MODEL) -> int:\n",
    "    \"\"\"Возвращает число токенов в строке для заданной модели\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "# Функция формирования запроса к chatGPT по пользовательскому вопросу и базе знаний\n",
    "def query_message(\n",
    "    query: str, # пользовательский запрос\n",
    "    df: pd.DataFrame, # DataFrame со столбцами text и embedding (база знаний)\n",
    "    model: str, # модель\n",
    "    token_budget: int # ограничение на число отсылаемых токенов в модель\n",
    ") -> str:\n",
    "    \"\"\"Возвращает сообщение для GPT с соответствующими исходными текстами, извлеченными из фрейма данных (базы знаний).\"\"\"\n",
    "    strings, relatednesses = strings_ranked_by_relatedness(query, df) # функция ранжирования базы знаний по пользовательскому запросу\n",
    "    # Шаблон инструкции для chatGPT\n",
    "    message = 'Use the below articles on Automotive industry to answer the subsequent question. If the answer cannot be found in the articles, write \"I could not find an answer.\"'\n",
    "    # Шаблон для вопроса\n",
    "    question = f\"\\n\\nQuestion: {query}\"\n",
    "\n",
    "    # Добавляем к сообщению для chatGPT релевантные строки из базы знаний, пока не выйдем за допустимое число токенов\n",
    "    for string in strings:\n",
    "        next_article = f'\\n\\nWikipedia article section:\\n\"\"\"\\n{string}\\n\"\"\"'\n",
    "        if (num_tokens(message + next_article + question, model=model) > token_budget):\n",
    "            break\n",
    "        else:\n",
    "            message += next_article\n",
    "    return message + question\n",
    "\n",
    "def ask(\n",
    "    query: str, # пользовательский запрос\n",
    "    df: pd.DataFrame = df, # DataFrame со столбцами text и embedding (база знаний)\n",
    "    model: str = GPT_MODEL, # модель\n",
    "    token_budget: int = 4096 - 500, # ограничение на число отсылаемых токенов в модель\n",
    "    print_message: bool = False, # нужно ли выводить сообщение перед отправкой\n",
    ") -> str:\n",
    "    \"\"\"Отвечает на вопрос, используя GPT и базу знаний.\"\"\"\n",
    "    # Формируем сообщение к chatGPT (функция выше)\n",
    "    message = query_message(query, df, model=model, token_budget=token_budget)\n",
    "    # Если параметр True, то выводим сообщение\n",
    "    if print_message:\n",
    "        print(message)\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You answer questions about Automotive industry.\"},\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ]\n",
    "    response = openai.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0 # гиперпараметр степени случайности при генерации текста. Влияет на то, как модель выбирает следующее слово в последовательности.\n",
    "    )\n",
    "    response_message = response.choices[0].message.content\n",
    "    return response_message"
   ],
   "id": "a4656be78a0e4469",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:56:06.449419Z",
     "start_time": "2024-05-18T12:56:02.963581Z"
    }
   },
   "cell_type": "code",
   "source": "ask(\"what is it Automotive industry ?\")",
   "id": "4ace59bd197391b2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query='what is it Automotive industry ?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The Automotive industry refers to the sector involved in the design, development, manufacturing, marketing, and selling of motor vehicles. This industry encompasses a wide range of activities related to automobiles, including car manufacturers, parts suppliers, dealerships, repair and maintenance services, and more. It plays a significant role in the global economy and is constantly evolving with advancements in technology, sustainability, and consumer preferences.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:57:32.139408Z",
     "start_time": "2024-05-18T12:57:32.133722Z"
    }
   },
   "cell_type": "code",
   "source": [
    "async def find_relevant_text(question_str) -> str:\n",
    "    strings, relatednesses = strings_ranked_by_relatedness(question_str, df, top_n=1)\n",
    "    \n",
    "    for string, relatedness in zip(strings, relatednesses):\n",
    "        print(f\"{relatedness=:.3f}\")\n",
    "        print(string)\n",
    "        return string\n",
    "    return False\n",
    "\n",
    "#print(await find_relevant_text(\"what is the best vehicle in the world?\"))c"
   ],
   "id": "147394dbdcf2f491",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T13:53:58.253140Z",
     "start_time": "2024-05-18T13:50:28.267813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import asyncio\n",
    "import logging\n",
    "from aiogram import Bot, Dispatcher, types\n",
    "from aiogram.filters.command import Command\n",
    "\n",
    "# Включаем логирование, чтобы не пропустить важные сообщения\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Замените \"YOUR_BOT_TOKEN\" на токен, который вы получили от BotFather\n",
    "API_TOKEN = os.environ[\"API_TOKEN\"] \n",
    "\n",
    "\n",
    "# Объект бота\n",
    "bot = Bot(token=API_TOKEN)\n",
    "# Диспетчер\n",
    "dp = Dispatcher()\n",
    "\n",
    "# Хэндлер на команду /start\n",
    "@dp.message(Command(\"help\"))\n",
    "async def cmd_help(message: types.Message):\n",
    "    await message.answer(\"The theme of this knowledge base is 'Automotive industry'\")\n",
    "    await message.answer(f\"Current size of knowledge base is {df.shape[0]} articles\")\n",
    "    await message.answer(f\"To ask question - you will need to send message with 'Question:' prefix.\")\n",
    "    await message.answer(f\"For example 'Question: what is the best vehicle in the world?' \")\n",
    "\n",
    "# Хэндлер на команду /start\n",
    "@dp.message()\n",
    "async def cmd_main(message: types.Message):\n",
    "\n",
    "    if message.text.lower().startswith(\"question:\"):\n",
    "        print(message.text)\n",
    "        question_edited = message.text.lower().replace(\"question:\", \"\").strip()\n",
    "        result = ask(question_edited)\n",
    "        await message.answer(result)\n",
    "        return\n",
    "    await message.answer(\"Use /help command to see the available commands\")\n",
    "    \n",
    "# Запуск процесса поллинга новых апдейтов\n",
    "async def main():\n",
    "    await dp.start_polling(bot)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())\n"
   ],
   "id": "3b998c5693dc87ef",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:aiogram.dispatcher:Start polling\n",
      "INFO:aiogram.dispatcher:Run polling for bot @bss_test_tg_kv_bot id=6387388299 - 'bss_test_tg'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What is the difference between Honda Civic and Toyota Supra?\n",
      "query='what is the difference between honda civic and toyota supra?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:aiogram.event:Update id=266353521 is handled. Duration 5330 ms by bot id=6387388299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What is the difference between Honda Civic and Toyota Supra?\n",
      "query='what is the difference between honda civic and toyota supra?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:aiogram.event:Update id=266353522 is handled. Duration 4966 ms by bot id=6387388299\n",
      "INFO:aiogram.event:Update id=266353523 is handled. Duration 3129 ms by bot id=6387388299\n",
      "WARNING:aiogram.dispatcher:Received SIGINT signal\n",
      "INFO:aiogram.dispatcher:Polling stopped for bot @bss_test_tg_kv_bot id=6387388299 - 'bss_test_tg'\n",
      "INFO:aiogram.dispatcher:Polling stopped\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T13:04:24.496121Z",
     "start_time": "2024-05-18T13:04:24.492379Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "536b9255079f05e0",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "40a977ed368a2e4f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
